{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(ticker):\n",
    "    '''\n",
    "    Function to scrape news headlines from finviz, a site for finance news. Returns a list of headlines with the corresponding date.m \n",
    "    Args:\n",
    "    - ticker: name of the ticker of a company (e.g. MSFT, AAPL, etc.).\n",
    "    '''\n",
    "    finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "    news_tables = {}\n",
    "\n",
    "    url = finwiz_url + ticker\n",
    "    req = Request(url=url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}) \n",
    "    response = urlopen(req)    \n",
    "\n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(response, features='lxml')\n",
    "\n",
    "    # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "    news_table = html.find(id='news-table')\n",
    "\n",
    "    # Add the table to our dictionary\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "    # Read one single day of headlines\n",
    "    company = news_tables[ticker]\n",
    "\n",
    "    # Get all the table rows tagged in HTML with <tr> \n",
    "    company_tr = company.findAll('tr')\n",
    "\n",
    "    news_headline = []\n",
    "    news_date = []\n",
    "\n",
    "    for i, table_row in enumerate(company_tr):\n",
    "        # Read the text of the element ‘a’ \n",
    "        a_text = table_row.a.text\n",
    "\n",
    "        # Read the text of the element ‘td’\n",
    "        td_text = table_row.td.text\n",
    "        \n",
    "        # Append the contents to the lists\n",
    "        news_headline.append(a_text)\n",
    "        news_date.append(td_text)\n",
    "\n",
    "        # Exit after scraping 100 news headlines\n",
    "        if i == 100:\n",
    "            break\n",
    "    \n",
    "    return (news_headline, news_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline, date = get_news('MSFT')\n",
    "df1 = pd.DataFrame({'Headline': headline, 'Date': date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Headline': headline, 'Date': date})\n",
    "for i in open('snp500.txt'):\n",
    "    try:\n",
    "        headline, date = get_news(i)\n",
    "        df2 = pd.DataFrame({'Headline': headline, 'Date': date})\n",
    "        df1 = df1.append(df2)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('stock_news_snp500.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5bb6742847f5c149c0b7d61ad97769a7d04a61d9c77a667e38fe9db356aeffe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
